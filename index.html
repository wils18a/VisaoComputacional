<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>Visão Computacional Avançada</title>

<style>
    body {
        margin: 0;
        background-color: #0a0a0a;
        color: #eee;
        font-family: 'Segoe UI', sans-serif;
        display: flex;
        flex-direction: column;
        align-items: center;
        overflow-x: hidden;
    }

    .header {
        padding: 15px;
        text-align: center;
    }

    .main-layout {
        display: flex;
        flex-wrap: wrap;
        justify-content: center;
        gap: 15px;
        padding: 10px;
        width: 100%;
    }

    .canvas-container {
        position: relative;
        background: #000;
        border: 2px solid #333;
        border-radius: 8px;
        line-height: 0;
        max-width: 95%; /* Garante que não estoure no mobile */
    }

    canvas {
        max-width: 100%;
        height: auto;
        display: block;
    }

    /* VÍDEO OCULTO MAS ATIVO */
    #videoInput {
        display: none;
    }

    .label-overlay {
        position: absolute;
        top: 10px;
        left: 10px;
        background: rgba(0,0,0,0.7);
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        z-index: 10;
        pointer-events: none;
    }

    #coords-display {
        color: #00ff00;
        font-weight: bold;
    }

    .status-msg {
        color: #ffcc00;
        margin-bottom: 10px;
        font-size: 14px;
    }
</style>
</head>

<body>

<div class="header">
    <h2>Detector de Trajetória</h2>
    <div id="status" class="status-msg">Aguardando OpenCV...</div>
</div>

<div class="main-layout">
    <div class="canvas-container">
        <div class="label-overlay">Câmera</div>
        <video id="videoInput" autoplay muted playsinline></video>
        <canvas id="canvasOutput"></canvas>
    </div>

    <div class="canvas-container">
        <div class="label-overlay">Trajetória (4s)</div>
        <canvas id="graphCanvas"></canvas>
    </div>
</div>

<div style="margin: 15px; font-size: 18px;">
    <span id="coords-display">Aguardando objeto...</span>
</div>

<script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady();"></script>

<script>
let video = document.getElementById('videoInput');
let canvasOutput = document.getElementById('canvasOutput');
let graphCanvas = document.getElementById('graphCanvas');
let ctxGraph = graphCanvas.getContext('2d');
let coordsDisplay = document.getElementById('coords-display');
let status = document.getElementById('status');

let src, gray, circles, cap;
let streaming = false;

// Média móvel para suavizar a detecção no celular
let historyX = [];
let historyY = [];
const MOVING_AVG_SIZE = 4;

let lastPosX = null;
let lastPosY = null;
let lastResetTime = Date.now();

function onOpenCvReady() {
    status.innerHTML = "OpenCV Carregado. Iniciando Câmera...";
    startCamera();
}

function startCamera() {
    // Restringir resolução para garantir performance no celular
    const constraints = {
        video: { 
            facingMode: "environment",
            width: { ideal: 640 },
            height: { ideal: 480 }
        },
        audio: false
    };

    navigator.mediaDevices.getUserMedia(constraints)
    .then(stream => {
        video.srcObject = stream;
        video.play();
    })
    .catch(err => {
        status.innerHTML = "Erro: " + err.name;
        status.style.color = "red";
    });

    // Iniciar apenas quando os metadados (largura/altura real) estiverem prontos
    video.onloadedmetadata = () => {
        if (!streaming) {
            initProcessor();
        }
    };
}

function initProcessor() {
    // Captura as dimensões reais que a câmera entregou
    const w = video.videoWidth;
    const h = video.videoHeight;

    canvasOutput.width = w;
    canvasOutput.height = h;
    graphCanvas.width = w;
    graphCanvas.height = h;

    // Inicializa matrizes do OpenCV
    src = new cv.Mat(h, w, cv.CV_8UC4);
    gray = new cv.Mat(h, w, cv.CV_8UC1);
    circles = new cv.Mat();
    cap = new cv.VideoCapture(video);

    clearGraph();

    streaming = true;
    status.innerHTML = "SISTEMA ONLINE";
    status.style.color = "#00ff00";

    requestAnimationFrame(processFrame);
}

function clearGraph() {
    ctxGraph.fillStyle = "#111";
    ctxGraph.fillRect(0, 0, graphCanvas.width, graphCanvas.height);
    
    // Grade de fundo
    ctxGraph.strokeStyle = "#222";
    for(let i=0; i<graphCanvas.width; i+=50) {
        ctxGraph.beginPath(); ctxGraph.moveTo(i,0); ctxGraph.lineTo(i, graphCanvas.height); ctxGraph.stroke();
    }
    for(let i=0; i<graphCanvas.height; i+=50) {
        ctxGraph.beginPath(); ctxGraph.moveTo(0,i); ctxGraph.lineTo(graphCanvas.width, i); ctxGraph.stroke();
    }

    lastPosX = null;
    lastPosY = null;
}

function processFrame() {
    if (!streaming) return;

    try {
        cap.read(src);
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
        
        // Reduz ruído para facilitar detecção no celular
        cv.GaussianBlur(gray, gray, new cv.Size(9, 9), 2, 2);

        // Parâmetros otimizados para performance mobile
        cv.HoughCircles(
            gray, circles,
            cv.HOUGH_GRADIENT,
            1.5,     // dp: Resolução inversa (maior = mais rápido/menos preciso)
            80,      // minDist: Distância mínima entre círculos
            80,      // param1: Sensibilidade do detector de bordas
            40,      // param2: Limiar de centro (menor = mais falsos positivos)
            20, 150  // min/max radius
        );

        // Desenha o vídeo original no canvas
        cv.imshow("canvasOutput", src);

        if (circles.cols > 0) {
            let rawX = circles.data32F[0];
            let rawY = circles.data32F[1];
            let radius = circles.data32F[2];

            // Média Móvel
            historyX.push(rawX);
            historyY.push(rawY);
            if (historyX.length > MOVING_AVG_SIZE) {
                historyX.shift();
                historyY.shift();
            }

            let avgX = historyX.reduce((a, b) => a + b) / historyX.length;
            let avgY = historyY.reduce((a, b) => a + b) / historyY.length;

            // Desenhar no Canvas de Feedback
            let ctxVideo = canvasOutput.getContext("2d");
            ctxVideo.beginPath();
            ctxVideo.arc(avgX, avgY, radius, 0, Math.PI * 2);
            ctxVideo.strokeStyle = "#00ff00";
            ctxVideo.lineWidth = 5;
            ctxVideo.stroke();

            // Atualizar Trajetória
            if (lastPosX !== null) {
                ctxGraph.beginPath();
                ctxGraph.moveTo(lastPosX, lastPosY);
                ctxGraph.lineTo(avgX, avgY);
                ctxGraph.strokeStyle = "#ff3333";
                ctxGraph.lineWidth = 3;
                ctxGraph.lineCap = "round";
                ctxGraph.stroke();
            }

            lastPosX = avgX;
            lastPosY = avgY;
            coordsDisplay.innerHTML = `X: ${Math.round(avgX)} | Y: ${Math.round(avgY)}`;
        }

        // Reset do gráfico a cada 4 segundos
        if (Date.now() - lastResetTime > 4000) {
            clearGraph();
            lastResetTime = Date.now();
        }

        requestAnimationFrame(processFrame);
    } catch (e) {
        console.log("Erro no processamento: ", e);
        requestAnimationFrame(processFrame);
    }
}
</script>

</body>
</html>
